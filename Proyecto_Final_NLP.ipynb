{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMf3k7F4Bp+enws1HqXahUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlaLS/Entregas-CoderHouse-Ciencia-de-Datos-III/blob/main/Proyecto_Final_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Análisis de Sentimientos en Tweets utilizando Machine Learning\n",
        "\n",
        "\n",
        "## Introducción\n",
        "En la era digital, plataformas como Twitter generan un flujo constante de opiniones y sentimientos de los usuarios. Comprender estas opiniones es esencial para empresas, investigadores y organizaciones, ya que les permite medir la percepción pública, tomar decisiones informadas y ajustar sus estrategias de marketing o servicio al cliente. Este proyecto se centra en el análisis de sentimientos en tweets, utilizando técnicas de Procesamiento de Lenguaje Natural (NLP) y modelos de Machine Learning para clasificar los sentimientos en tres categorías: positivo, negativo y neutral.\n",
        "\n",
        "## Objetivos\n",
        "**Objetivo General**\n",
        "\n",
        "Desarrollar un modelo de Machine Learning eficaz para clasificar tweets en tres categorías de sentimientos: positivo, negativo y neutral.\n",
        "\n",
        "**Objetivos Específicos**\n",
        "\n",
        "Realizar un análisis exploratorio de datos para entender las características del conjunto de datos.\n",
        "\n",
        "Diseñar y aplicar un pipeline de preprocesamiento para limpiar y normalizar el texto.\n",
        "\n",
        "Entrenar varios modelos de Machine Learning para clasificar los sentimientos en los tweets.\n",
        "\n",
        "Implementar una evaluación exhaustiva de los modelos para identificar el más eficiente.\n",
        "\n",
        "Validar el modelo seleccionado mediante predicciones en nuevos ejemplos y analizar su rendimiento.\n",
        "\n",
        "## Metodología\n",
        "\n",
        "**Dataset**\n",
        "\n",
        "Se utilizó el dataset disponible en el repositorio de GitHub: \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\". Este dataset contiene tweets clasificados originalmente en etiquetas binarias (positivo y negativo), que fueron reclasificados en tres categorías: positivo, negativo y neutral."
      ],
      "metadata": {
        "id": "huIvW652SRfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uqplef7b2JbJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4880dd7c-5b14-4c40-b0ba-e1ca127fffd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Liberías Necesarias\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Carga de datos\n",
        "data_url = \"https://raw.githubusercontent.com/dD2405/Twitter_Sentiment_Analysis/master/train.csv\"\n",
        "data = pd.read_csv(data_url)\n",
        "\n",
        "# Primeras filas del dataset\n",
        "print(\"Dataset original:\")\n",
        "print(data.head())"
      ],
      "metadata": {
        "id": "AiBDzfFL2PGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e6771f-fc83-45d2-c7aa-fa3042f851f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset original:\n",
            "   id  label                                              tweet\n",
            "0   1      0   @user when a father is dysfunctional and is s...\n",
            "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
            "2   3      0                                bihday your majesty\n",
            "3   4      0  #model   i love u take with u all the time in ...\n",
            "4   5      0             factsguide: society now    #motivation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Procesamiento de Datos**\n",
        "\n",
        "*Limpieza de Datos:*\n",
        "\n",
        "Se eliminaron enlaces, menciones, caracteres especiales y stopwords irrelevantes.\n",
        "\n",
        "*Reclasificación de Sentimientos:*\n",
        "\n",
        "Tweets con palabras clave positivas (“love”, “amazing”) fueron etiquetados como positivos.\n",
        "\n",
        "Tweets con palabras clave negativas (“worst”, “bad”) fueron etiquetados como negativos.\n",
        "\n",
        "Los tweets que no contenían palabras clave específicas se clasificaron como neutrales.\n",
        "\n",
        "*Vectorización*:\n",
        "\n",
        "Se utilizó TfidfVectorizer para convertir el texto en representaciones numéricas.\n",
        "\n",
        "**Modelos Implementados**\n",
        "\n",
        "*Naive Bayes Multinomial:*\n",
        "\n",
        " Un modelo base conocido por su eficiencia en tareas de clasificación de texto.\n",
        "\n",
        "*Regresión Logística:*\n",
        "\n",
        "Optimizada con GridSearchCV para encontrar los mejores hiperparámetros.\n",
        "\n",
        "*Random Forest:*\n",
        "\n",
        "Utilizado para capturar relaciones no lineales entre las características.\n",
        "\n",
        "**Manejo del Desbalanceo de Clases**\n",
        "\n",
        "Se aplicó SMOTE (Synthetic Minority Oversampling Technique) para balancear las clases durante el entrenamiento."
      ],
      "metadata": {
        "id": "fgqiUz0ITQQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Exploración y limpieza del dataset\n",
        "# Solo columnas necesarias: texto y sentimiento\n",
        "data = data[[\"label\", \"tweet\"]]\n",
        "data = data.rename(columns={\"label\": \"sentiment\", \"tweet\": \"text\"})"
      ],
      "metadata": {
        "id": "MBMiGtDyOvOE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Verificar valores nulos\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "# Reclasificación para incluir la clase neutral\n",
        "def reclasificar_sentimiento(row):\n",
        "    positive_keywords = [\"love\", \"great\", \"amazing\", \"excellent\", \"good\"]\n",
        "    negative_keywords = [\"worst\", \"bad\", \"awful\", \"terrible\", \"hate\"]\n",
        "\n",
        "    text = row[\"text\"].lower()\n",
        "\n",
        "    if any(word in text for word in positive_keywords):\n",
        "        return 1  # Positivo\n",
        "    elif any(word in text for word in negative_keywords):\n",
        "        return 0  # Negativo\n",
        "    else:\n",
        "        return 2  # Neutral\n",
        "\n",
        "data[\"sentiment\"] = data.apply(reclasificar_sentimiento, axis=1)\n",
        "\n",
        "# Mostrar distribución de sentimientos\n",
        "print(\"\\nDistribución de sentimientos:\")\n",
        "print(data[\"sentiment\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhgyhwQ5O1yx",
        "outputId": "17cd8fc7-e482-40d9-a6cb-5137b95cd2e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Distribución de sentimientos:\n",
            "sentiment\n",
            "2    25606\n",
            "1     5561\n",
            "0      795\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Preprocesamiento del texto\n",
        "def clean_text_advanced(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Eliminar enlaces, menciones y caracteres especiales\n",
        "    text = re.sub(r'http\\S+', '', text)  # Eliminar enlaces\n",
        "    text = re.sub(r'@\\w+', '', text)     # Eliminar menciones\n",
        "    text = re.sub(r'[^A-Za-z\\s]', '', text)  # Eliminar caracteres especiales\n",
        "\n",
        "    # Convertir a minúsculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Tokenizar y lematizar palabras, excluyendo stopwords\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "\n",
        "    return ' '.join(tokens)"
      ],
      "metadata": {
        "id": "9s8MbVS12hBL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#5. Aplicar limpieza\n",
        "X = data[\"text\"].apply(clean_text_advanced)\n",
        "y = data[\"sentiment\"]\n",
        "\n",
        "# Dividir datos en entrenamiento y prueba\n",
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ],
      "metadata": {
        "id": "wWuiji7kRCOD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#6. Vectorización del texto\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_vec = vectorizer.fit_transform(X_train_raw)\n",
        "X_test_vec = vectorizer.transform(X_test_raw)\n",
        "\n",
        "# 7. Aplicar SMOTE para balancear clases\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n"
      ],
      "metadata": {
        "id": "Djtoq8uudjNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e03cc83-a2d3-42d2-b4c0-fb0f6209ac17"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Modelos de Machine Learning\n",
        "# a. Naive Bayes\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_vec, y_train)\n",
        "nb_preds = nb_model.predict(X_test_vec)\n",
        "print(\"\\nNaive Bayes:\")\n",
        "print(classification_report(y_test, nb_preds))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D2bCQGHCdWUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea85bddf-f492-4f9c-a056-eaf6813f6737"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.23      0.71      0.35       159\n",
            "           1       0.54      0.85      0.66      1112\n",
            "           2       0.96      0.78      0.86      5122\n",
            "\n",
            "    accuracy                           0.79      6393\n",
            "   macro avg       0.58      0.78      0.62      6393\n",
            "weighted avg       0.87      0.79      0.81      6393\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# b. Logistic Regression con GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=1000, class_weight='balanced', multi_class='ovr'), param_grid, cv=3, scoring='f1_macro')\n",
        "grid.fit(X_train_vec, y_train)\n",
        "\n",
        "# Mejor modelo Logistic Regression\n",
        "best_lr = grid.best_estimator_\n",
        "print(\"\\nMejores hiperparámetros Logistic Regression:\", grid.best_params_)\n",
        "\n",
        "lr_preds = best_lr.predict(X_test_vec)\n",
        "print(\"\\nLogistic Regression:\")\n",
        "print(classification_report(y_test, lr_preds))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlIZS_rHJVfe",
        "outputId": "181223ee-5bd7-4501-9715-cfa15e5d51fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Mejores hiperparámetros Logistic Regression: {'C': 10, 'solver': 'liblinear'}\n",
            "\n",
            "Logistic Regression:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.84      0.76       159\n",
            "           1       0.85      0.89      0.87      1112\n",
            "           2       0.97      0.96      0.96      5122\n",
            "\n",
            "    accuracy                           0.94      6393\n",
            "   macro avg       0.84      0.90      0.86      6393\n",
            "weighted avg       0.94      0.94      0.94      6393\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# c. Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train_vec, y_train)\n",
        "rf_preds = rf_model.predict(X_test_vec)\n",
        "print(\"\\nRandom Forest:\")\n",
        "print(classification_report(y_test, rf_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlddRUZPJbgT",
        "outputId": "4f6558a2-6318-4a9d-c383-b1ec5572a3db"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Random Forest:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.84      0.84       159\n",
            "           1       0.91      0.88      0.90      1112\n",
            "           2       0.97      0.98      0.97      5122\n",
            "\n",
            "    accuracy                           0.96      6393\n",
            "   macro avg       0.91      0.90      0.90      6393\n",
            "weighted avg       0.96      0.96      0.96      6393\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Observaciones\n",
        "\n",
        "**Naive Bayes**\n",
        "\n",
        "*Desbalance de clases:*  La clase 2 domina el dataset, lo que hace que el modelo priorice su predicción, penalizando el desempeño en las clases 0 y 1.\n",
        "\n",
        "*Clase 0*:  El modelo tiene serias dificultades para identificar correctamente esta clase (baja precisión y F1-score).\n",
        "\n",
        "*Clase 1:* Aunque tiene un desempeño aceptable, aún hay margen para mejorar su precisión.\n",
        "\n",
        "**Logistic Regression**\n",
        "\n",
        "*Clase 0:* El modelo tiene un rendimiento aceptable considerando que es la clase minoritaria. Sin embargo, la precisión moderada (0.69) indica que aún se confunde con las otras clases en ciertos casos.\n",
        "\n",
        "*Clase 1:* El modelo maneja esta clase con alta precisión y recall, mostrando un equilibrio sólido en su clasificación.\n",
        "\n",
        "*Clase 2:* Como clase dominante en el dataset, el modelo sobresale con casi perfecta precisión y recall, lo que resulta en un excelente F1-score (0.96).\n",
        "\n",
        "**Random Forest**\n",
        "\n",
        "*Clase 0:* A pesar de ser minoritaria, el modelo la identifica con alta precisión y recall, lo que sugiere que Random Forest maneja bien el desbalance de clases.\n",
        "\n",
        "*Clase 1:* Consistencia en el rendimiento con un balance sólido entre precisión y recall.\n",
        "\n",
        "*Clase 2:*  Dominante en el dataset, el modelo sobresale al clasificarla con casi perfecta precisión y recall.\n"
      ],
      "metadata": {
        "id": "BI9TXGGw2ClG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 9. Comparación de modelos\n",
        "print(\"\\nAccuracy Scores:\")\n",
        "print(f\"Naive Bayes: {accuracy_score(y_test, nb_preds):.2f}\")\n",
        "print(f\"Logistic Regression: {accuracy_score(y_test, lr_preds):.2f}\")\n",
        "print(f\"Random Forest: {accuracy_score(y_test, rf_preds):.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P94x_o3xJeWk",
        "outputId": "3523d588-bc76-407b-c4f1-bdee1af44519"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Accuracy Scores:\n",
            "Naive Bayes: 0.79\n",
            "Logistic Regression: 0.94\n",
            "Random Forest: 0.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comentarios**\n",
        "\n",
        "Random Forest tiene el mejor desempeño en términos de accuracy y métricas F1 para todas las clases, manejando bien tanto las mayoritarias como las minoritarias.\n",
        "\n",
        "Comparado con Logistic Regression, tiene una ligera ventaja, especialmente en la precisión de las clases minoritarias.\n",
        "\n",
        "Supera significativamente a Naive Bayes, especialmente en la clase 0, donde Naive Bayes tiene dificultades.\n",
        "\n",
        " Por su excelente equilibrio entre precisión, recall y F1-score Random Forest se convierte en la mejor opción."
      ],
      "metadata": {
        "id": "E7Pdx4ZK3r1M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 10. Desafío del modelo\n",
        "best_model = best_lr\n",
        "new_tweets = [\n",
        "    \"I love this product! It's amazing.\",\n",
        "    \"This is the worst experience I've ever had.\",\n",
        "    \"I'm not sure how I feel about this.\"\n",
        "]\n",
        "new_tweets_cleaned = [clean_text_advanced(tweet) for tweet in new_tweets]\n",
        "new_tweets_vec = vectorizer.transform(new_tweets_cleaned)\n",
        "new_preds = best_model.predict(new_tweets_vec)\n",
        "\n",
        "print(\"\\nPredicciones para nuevos ejemplos:\")\n",
        "for tweet, pred in zip(new_tweets, new_preds):\n",
        "    sentiment = \"Neutral\" if pred == 2 else \"Positivo\" if pred == 1 else \"Negativo\"\n",
        "    print(f\"Tweet: {tweet}\\nPredicción: {sentiment}\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymrUPew0JhXX",
        "outputId": "0ff2d5e0-b51d-4608-9cea-c0956e0a8347"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicciones para nuevos ejemplos:\n",
            "Tweet: I love this product! It's amazing.\n",
            "Predicción: Positivo\n",
            "\n",
            "Tweet: This is the worst experience I've ever had.\n",
            "Predicción: Negativo\n",
            "\n",
            "Tweet: I'm not sure how I feel about this.\n",
            "Predicción: Neutral\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Análisis de las Predicciones para Nuevos Ejemplos\n",
        "\n",
        "1. Ejemplo: \"I love this product! It's amazing.\"\n",
        "\n",
        "**Predicción: Positivo**\n",
        "\n",
        "La predicción es consistente con el sentimiento del tweet, ya que las palabras clave como \"love\" y \"amazing\" son fuertemente asociadas con emociones positivas.\n",
        "La precisión del modelo para identificar textos positivos parece ser sólida, asumiendo que se basa en las características léxicas y el tono emocional del tweet.Este resultado respalda la capacidad del modelo para identificar sentimientos explícitos positivos.\n",
        "\n",
        "\n",
        "2. Ejemplo: \"This is the worst experience I've ever had.\"\n",
        "\n",
        "**Predicción: Negativo**\n",
        "\n",
        "La predicción es correcta, ya que términos como \"worst\" y \"experience\" en este contexto tienen una connotación clara de insatisfacción y descontento.\n",
        "El modelo demuestra un buen manejo del sentimiento negativo explícito. Este tweet representa un ejemplo típico y fácil de clasificar debido a su lenguaje explícito.\n",
        "\n",
        "\n",
        "3. Ejemplo: \"I'm not sure how I feel about this.\"\n",
        "\n",
        "**Predicción: Neutral**\n",
        "\n",
        "La predicción es razonable. El lenguaje del tweet no contiene palabras explícitamente positivas o negativas, y sugiere ambigüedad emocional (\"not sure\", \"how I feel\").\n",
        "La capacidad del modelo para identificar sentimientos neutros parece estar funcionando correctamente, basándose en el contexto y la falta de términos emocionalmente cargados.\n",
        "\n",
        "# Conclusiones\n",
        "\n",
        "##Textos explícitos:\n",
        "Muestra precisión al identificar emociones claras, como en los ejemplos positivo y negativo.\n",
        "\n",
        "## Ambigüedad:\n",
        "\n",
        "La predicción neutral sugiere que el modelo maneja correctamente casos donde no hay polaridad evidente."
      ],
      "metadata": {
        "id": "WfOOYUED5MA9"
      }
    }
  ]
}